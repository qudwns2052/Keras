{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMDB란 영화리뷰에서, 긍정과 부정이 있는데 이 값을 한쌍의 데이터 값으로 만든 것이다.\n",
    "50000개 중 25000개를 트레이닝, 나머지 25000개는 테스팅 샘플이다.\n",
    "긍정 or 부정이라는 이진 특성을 갖고 있으므로, 바이너리 분류를 목적으로 한다.\n",
    "\n",
    "여기서는 가장 자주 사용되는 20000개의 단어만 포함했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "25000개의 트레이닝 샘플을, 20000 / 5000으로 쪼개 각각 트레이닝샘플/트레이닝 이후 테스트 샘플로 나누었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[20000:]\n",
    "y_val = y_train[20000:]\n",
    "x_train = x_train[:20000]\n",
    "y_train = y_train[:20000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "밑에서 사용되는 sequence.pad_sequences는, 하나의 리뷰 샘플의 크기를 200이라는 일정한 크기로 맞춰주기 위해 사용하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=200)\n",
    "x_val = sequence.pad_sequences(x_val, maxlen=200)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "임베딩을 통해 단어간의 연관성을 파악한 벡터가 만들어지기 때문에 훈련하는데 도움이 된다.\n",
    "\n",
    "LSTM은, long short term memory의 약자이다. 이건 RNN 신경망에서 변형된 형태이다. RNN에서는 훈련이 길어지면, 가중치를 계속 곱하게 되고, 이렇게 되면 결국 0에 가까운 값이 나오기 때문에, 훈련이 잘 되지 않는다. 때문에 LSTM에서는 누적해서 추가하기 보다는, 새로운 input을 보고 기억 데이터의 일부를 삭제한다고 한다.....\n",
    "\n",
    "sigmoid함수는 지금 이진 분류를 하기 때문에 사용했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(20000, 128))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 128)         2560000   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,691,713\n",
      "Trainable params: 2,691,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\qudwn\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/25\n",
      "20000/20000 [==============================] - 136s 7ms/step - loss: 0.4560 - acc: 0.7843 - val_loss: 0.3516 - val_acc: 0.8538\n",
      "Epoch 2/25\n",
      "20000/20000 [==============================] - 100s 5ms/step - loss: 0.2275 - acc: 0.9144 - val_loss: 0.3306 - val_acc: 0.8720\n",
      "Epoch 3/25\n",
      "20000/20000 [==============================] - 90s 5ms/step - loss: 0.1309 - acc: 0.9537 - val_loss: 0.3961 - val_acc: 0.8584\n",
      "Epoch 4/25\n",
      "20000/20000 [==============================] - 93s 5ms/step - loss: 0.0997 - acc: 0.9652 - val_loss: 0.5230 - val_acc: 0.8564\n",
      "Epoch 5/25\n",
      "20000/20000 [==============================] - 92s 5ms/step - loss: 0.1242 - acc: 0.9519 - val_loss: 0.4720 - val_acc: 0.8276\n",
      "Epoch 6/25\n",
      "20000/20000 [==============================] - 92s 5ms/step - loss: 0.0709 - acc: 0.9772 - val_loss: 0.5286 - val_acc: 0.8518\n",
      "Epoch 7/25\n",
      "20000/20000 [==============================] - 92s 5ms/step - loss: 0.0362 - acc: 0.9888 - val_loss: 0.5903 - val_acc: 0.8586\n",
      "Epoch 8/25\n",
      "20000/20000 [==============================] - 94s 5ms/step - loss: 0.0240 - acc: 0.9928 - val_loss: 0.5912 - val_acc: 0.8504\n",
      "Epoch 9/25\n",
      "20000/20000 [==============================] - 102s 5ms/step - loss: 0.0205 - acc: 0.9940 - val_loss: 0.6968 - val_acc: 0.8354\n",
      "Epoch 10/25\n",
      "20000/20000 [==============================] - 102s 5ms/step - loss: 0.0229 - acc: 0.9938 - val_loss: 0.8544 - val_acc: 0.8416\n",
      "Epoch 11/25\n",
      "20000/20000 [==============================] - 101s 5ms/step - loss: 0.0243 - acc: 0.9924 - val_loss: 0.6807 - val_acc: 0.8578\n",
      "Epoch 12/25\n",
      "20000/20000 [==============================] - 112s 6ms/step - loss: 0.0267 - acc: 0.9931 - val_loss: 0.6312 - val_acc: 0.8458\n",
      "Epoch 13/25\n",
      "20000/20000 [==============================] - 128s 6ms/step - loss: 0.0249 - acc: 0.9932 - val_loss: 0.7891 - val_acc: 0.8526\n",
      "Epoch 14/25\n",
      "20000/20000 [==============================] - 173s 9ms/step - loss: 0.0144 - acc: 0.9963 - val_loss: 0.7867 - val_acc: 0.8500\n",
      "Epoch 15/25\n",
      "20000/20000 [==============================] - 181s 9ms/step - loss: 0.0064 - acc: 0.9985 - val_loss: 0.7693 - val_acc: 0.8396\n",
      "Epoch 16/25\n",
      "20000/20000 [==============================] - 182s 9ms/step - loss: 0.0230 - acc: 0.9923 - val_loss: 0.7348 - val_acc: 0.8480\n",
      "Epoch 17/25\n",
      "20000/20000 [==============================] - 190s 10ms/step - loss: 0.0157 - acc: 0.9950 - val_loss: 0.8446 - val_acc: 0.8486\n",
      "Epoch 18/25\n",
      "20000/20000 [==============================] - 193s 10ms/step - loss: 0.0173 - acc: 0.9952 - val_loss: 0.7062 - val_acc: 0.8388\n",
      "Epoch 19/25\n",
      "20000/20000 [==============================] - 210s 11ms/step - loss: 0.0068 - acc: 0.9979 - val_loss: 0.9293 - val_acc: 0.8584\n",
      "Epoch 20/25\n",
      "20000/20000 [==============================] - 219s 11ms/step - loss: 0.0109 - acc: 0.9969 - val_loss: 0.8023 - val_acc: 0.8482\n",
      "Epoch 21/25\n",
      "20000/20000 [==============================] - 215s 11ms/step - loss: 0.0226 - acc: 0.9926 - val_loss: 0.7179 - val_acc: 0.8364\n",
      "Epoch 22/25\n",
      "20000/20000 [==============================] - 191s 10ms/step - loss: 0.0061 - acc: 0.9987 - val_loss: 0.7670 - val_acc: 0.8504\n",
      "Epoch 23/25\n",
      "20000/20000 [==============================] - 174s 9ms/step - loss: 0.0047 - acc: 0.9991 - val_loss: 0.9386 - val_acc: 0.8554\n",
      "Epoch 24/25\n",
      "20000/20000 [==============================] - 182s 9ms/step - loss: 0.0075 - acc: 0.9978 - val_loss: 0.8506 - val_acc: 0.8424\n",
      "Epoch 25/25\n",
      "20000/20000 [==============================] - 180s 9ms/step - loss: 0.0061 - acc: 0.9982 - val_loss: 0.9602 - val_acc: 0.8192\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train, y_train, epochs=25, batch_size=64, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 98s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "result=model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.093171546549797\n"
     ]
    }
   ],
   "source": [
    "print(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.80624\n"
     ]
    }
   ],
   "source": [
    "print(result[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
