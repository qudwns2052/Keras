{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMDB란 영화리뷰에서, 긍정과 부정이 있는데 이 값을 한쌍의 데이터 값으로 만든 것이다. 50000개 중 25000개를 트레이닝, 나머지 25000개는 테스팅 샘플이다. 긍정 or 부정이라는 이진 특성을 갖고 있으므로, 바이너리 분류를 목적으로 한다.\n",
    "\n",
    "여기서는 가장 자주 사용되는 20000개의 단어만 포함했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=20000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "25000개의 트레이닝 샘플을, 20000 / 5000으로 쪼개 각각 트레이닝샘플/트레이닝 이후 테스트 샘플로 나누었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[20000:]\n",
    "y_val = y_train[20000:]\n",
    "x_train = x_train[:20000]\n",
    "y_train = y_train[:20000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "밑에서 사용되는 sequence.pad_sequences는, 하나의 리뷰 샘플의 크기를 200이라는 일정한 크기로 맞춰주기 위해 사용하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=200)\n",
    "x_val = sequence.pad_sequences(x_val, maxlen=200)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "임베딩을 통해 단어간의 연관성을 파악한 벡터가 만들어지기 때문에 훈련하는데 도움이 된다.\n",
    "\n",
    "sigmoid함수는 지금 이진 분류를 하기 때문에 사용했다.\n",
    "\n",
    "dropout은 과대적합을 방지하기 위해 추가한 층이다.\n",
    "\n",
    "Conv1D은 2차원에서도 쓰이지만, 1차원에서도 쓰일 수 있다. RNN보다는 계산 비용이 더 적게 들고 다양한 패턴을 인식할 수 있다. 하지만 연산량이 많아지는 문제점이 있다.\n",
    "\n",
    "Pooling은 벡터의 특징적인 값 하나를 추출하는 과정이다. 이를 통해 과대적합을 해결하는데 많은 기여를 할 수 있다. GlobalMaxPooling은 가장 큰 특징적인 값을 가져오는 pooling이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\qudwn\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\qudwn\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(20000, 128, input_length=200))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(256,\n",
    "                 3,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1))\n",
    "\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 200, 128)          2560000   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 200, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 198, 256)          98560     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,691,585\n",
      "Trainable params: 2,691,585\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\qudwn\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\qudwn\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/25\n",
      "20000/20000 [==============================] - 105s 5ms/step - loss: 0.4660 - acc: 0.7590 - val_loss: 0.3039 - val_acc: 0.8708\n",
      "Epoch 2/25\n",
      "20000/20000 [==============================] - 103s 5ms/step - loss: 0.2161 - acc: 0.9143 - val_loss: 0.2644 - val_acc: 0.8904\n",
      "Epoch 3/25\n",
      "20000/20000 [==============================] - 103s 5ms/step - loss: 0.0847 - acc: 0.9731 - val_loss: 0.3088 - val_acc: 0.8876\n",
      "Epoch 4/25\n",
      "20000/20000 [==============================] - 103s 5ms/step - loss: 0.0228 - acc: 0.9947 - val_loss: 0.3573 - val_acc: 0.8956\n",
      "Epoch 5/25\n",
      "20000/20000 [==============================] - 104s 5ms/step - loss: 0.0066 - acc: 0.9992 - val_loss: 0.4069 - val_acc: 0.8946\n",
      "Epoch 6/25\n",
      "20000/20000 [==============================] - 103s 5ms/step - loss: 0.0027 - acc: 0.9997 - val_loss: 0.4452 - val_acc: 0.8898\n",
      "Epoch 7/25\n",
      "20000/20000 [==============================] - 106s 5ms/step - loss: 0.0012 - acc: 0.9999 - val_loss: 0.4611 - val_acc: 0.8938\n",
      "Epoch 8/25\n",
      "20000/20000 [==============================] - 109s 5ms/step - loss: 5.9455e-04 - acc: 1.0000 - val_loss: 0.4838 - val_acc: 0.8896\n",
      "Epoch 9/25\n",
      "20000/20000 [==============================] - 106s 5ms/step - loss: 4.8559e-04 - acc: 1.0000 - val_loss: 0.5059 - val_acc: 0.8908\n",
      "Epoch 10/25\n",
      "20000/20000 [==============================] - 105s 5ms/step - loss: 2.4776e-04 - acc: 1.0000 - val_loss: 0.5218 - val_acc: 0.8918\n",
      "Epoch 11/25\n",
      "20000/20000 [==============================] - 108s 5ms/step - loss: 1.5907e-04 - acc: 1.0000 - val_loss: 0.5344 - val_acc: 0.8902\n",
      "Epoch 12/25\n",
      "20000/20000 [==============================] - 106s 5ms/step - loss: 1.3440e-04 - acc: 1.0000 - val_loss: 0.5561 - val_acc: 0.8938\n",
      "Epoch 13/25\n",
      "20000/20000 [==============================] - 109s 5ms/step - loss: 1.2943e-04 - acc: 1.0000 - val_loss: 0.5678 - val_acc: 0.8900\n",
      "Epoch 14/25\n",
      "20000/20000 [==============================] - 106s 5ms/step - loss: 1.0586e-04 - acc: 1.0000 - val_loss: 0.5837 - val_acc: 0.8910\n",
      "Epoch 15/25\n",
      "20000/20000 [==============================] - 107s 5ms/step - loss: 6.6449e-05 - acc: 1.0000 - val_loss: 0.5985 - val_acc: 0.8892\n",
      "Epoch 16/25\n",
      "20000/20000 [==============================] - 107s 5ms/step - loss: 4.8776e-05 - acc: 1.0000 - val_loss: 0.6072 - val_acc: 0.8896\n",
      "Epoch 17/25\n",
      "20000/20000 [==============================] - 103s 5ms/step - loss: 3.2727e-05 - acc: 1.0000 - val_loss: 0.6144 - val_acc: 0.8904\n",
      "Epoch 18/25\n",
      "20000/20000 [==============================] - 102s 5ms/step - loss: 3.4445e-05 - acc: 1.0000 - val_loss: 0.6308 - val_acc: 0.8898\n",
      "Epoch 19/25\n",
      "20000/20000 [==============================] - 103s 5ms/step - loss: 2.5040e-05 - acc: 1.0000 - val_loss: 0.6472 - val_acc: 0.8912\n",
      "Epoch 20/25\n",
      "20000/20000 [==============================] - 105s 5ms/step - loss: 1.6459e-05 - acc: 1.0000 - val_loss: 0.6463 - val_acc: 0.8902\n",
      "Epoch 21/25\n",
      "20000/20000 [==============================] - 104s 5ms/step - loss: 1.5223e-05 - acc: 1.0000 - val_loss: 0.6608 - val_acc: 0.8902\n",
      "Epoch 22/25\n",
      "20000/20000 [==============================] - 104s 5ms/step - loss: 1.2621e-05 - acc: 1.0000 - val_loss: 0.6688 - val_acc: 0.8906\n",
      "Epoch 23/25\n",
      "20000/20000 [==============================] - 96s 5ms/step - loss: 3.0569e-05 - acc: 1.0000 - val_loss: 0.7101 - val_acc: 0.8846\n",
      "Epoch 24/25\n",
      "20000/20000 [==============================] - 89s 4ms/step - loss: 0.0597 - acc: 0.9788 - val_loss: 0.4410 - val_acc: 0.8812\n",
      "Epoch 25/25\n",
      "20000/20000 [==============================] - 92s 5ms/step - loss: 0.0134 - acc: 0.9956 - val_loss: 0.5378 - val_acc: 0.8830\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train, y_train, epochs=25, batch_size=64, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 40s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "result=model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5949737614390254\n"
     ]
    }
   ],
   "source": [
    "print(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.86788\n"
     ]
    }
   ],
   "source": [
    "print(result[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
